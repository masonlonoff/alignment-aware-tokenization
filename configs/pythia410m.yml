model_name: "EleutherAI/pythia-410m"
precision: "bf16"
lora:
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules: ["Wqkv", "out_proj", "fc_in", "fc_out"]
train:
  lr: 2.0e-4
  batch_size: 64
  steps: 2000
  warmup_steps: 100
drift:
  lambda: 0.5
  margin: 0.2
  layer: 10
data:
  unlabeled_stream: "segyges/OpenWebText2"
  anchors: "data/anchors.jsonl"
  neutrals: "data/neutral_lookalikes.jsonl"
eval:
  u_dev_sample: 20000
